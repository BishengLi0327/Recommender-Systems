# Multi-Interest Network with Dynamic Routing for Recommendation at Tmall (MIND)

https://arxiv.org/abs/1904.08030

**Main Contribution**:

1. To capture diverse intertests of users from user behaviour, this paper designed the multi-interest extractor layer, which utilizes dynamic routing to adaptively aggregate user's historial behaviours into user representation vectors.
2. By using user representation vectors produced by the multi-interest extractor layer and a newly proposed label-aware attention layer, a deep neural network is built for personalized recommendation tasks. Comnpare with existing methods, MIND shows superior performance on several public datasets and one industrial dataset from Tmall.
3. A system is constructed to implement the whole pipeline for data collecting, model training and online serving to deploy MIND for serving billion-scale users at Tmall. The deployed system significantly improves the click-through rate of the home page on Mobile Tmall APP.


**MIND Framework**

<img width="810" alt="image" src="https://user-images.githubusercontent.com/49403324/208366456-f2242c88-df57-4e45-89a3-f69c49528a63.png">


**MIND**

Industrial recommender systems usually consist of the matching stage and the ranking stage, in order to handle the billion-scale of users and items. The matching stage retrieves candidate items relevant to user interests, while the ranking stage sorts candidate items by user interests. Thus, the most critical ability is to model and
represent user interests for either stage.

1. Problem Formalization

    The objective of the matching stage for industrial RS is to retrieve a subset of items from the billion-scale item pool $\mathcal{I}$ for each user $u \in \mathcal{U}$ such that the subset contains only thousands of items and each item is relevant to interests of the user. In order to achieve this objective, historial data generated by RS is collected for building a mathcing machine. Specifically, each instance can be represented by a tuple $(\mathcal{I}\_{u}, \mathcal{P}\_{u}, \mathcal{F}\_{i})$, where $\mathcal{I}\_{u}$ denotes the set of items interacted by user $u$, $\mathcal{P}\_{u}$ the basic profiles of user $u$, $\mathcal{F}\_{i}$ the features of target item.
    
    The core task of MIND is to learn a function for mapping raw features into user representations, which can be formulated as:
    $$V_{u} = f_{user} (\mathcal{I}\_{u}, \mathcal{P}\_{u})$$
    where $V_{u} = (\vec{v}\_{u}^{1}, \cdots, \vec{v}\_{u}^{K}) \in \mathcal{R}^{d \times K}$ denotes the representation vectors of user $u$, $d$ the dimensionality, $K$ the number of representation vectors.
    
    The represenmtation vector of target item $i$ can be obtained by an embedding functionas
    $$\vec{e}\_{i} = f_{item}(\mathcal{F}\_{i})$$
    where $\vec{e}\_{i} \in \mathbb{R}^{d \times 1}$ denotes the representation vector of item $i$.
    
    When user represewntation vectors and item representation vector are learnt, top $N$ candidate items are retrieved according to the scoring function
    $$f_{score}(V_{u}, \vec{e}\_{i}) = \max_{1 \leq k \leq K} \vec{e}\_{i}^{T} \vec{v}\_{u}^{k}$$

2. Embedding & Pooling Layer

    As shown in the above frameworkm, the input of MIND consisits three of three groups
    - user profile $\mathcal{P}\_{u}$
    - user behaviour $\mathcal{I}\_{u}$
    - label item $\mathcal{F}\_{i}$

    Each group contains several categorical id features, and these features are of extremely high dimensionality, MIND adopt the widely used embedding techinque to embed these id features into low-dimension dense vectors. 

3. Multi-Interest Extractor Layer

    Representing user interests by one representation vector can be the bottleneck for capturing diverse interests of users, because we have to compress all information related with diverse interests of users into one representation vector. Instead, in MIND we use multiple representation vectors to express distinct interests of users seperately. By this way, diverse interests of users are considered seperately in the matching stage, enabling more accurate item retrieve for every aspect of interest. In MIND, we design the multi-interest extractor layer for clustering historical behaviours and inferring representation vectors for resulted clusters.
    
    1. Dynamic Routing Revisit

        The goal of dynamic routing is to compute the values of high-level capsules given the values of low-level capsules in an iterative way. In each iteration, given low-level capsures $i \in {1, \cdots, m}$ with corresponding vectors $\vec{c}\_{i}^{l} \in \mathbb{R}^{N_{l} \times 1}$, $i \in {1, \cdots, m}$ and high level capsures $j \in {1, \cdots, n}$ with corresponding vectors $\vec{c}\_{j}^{h} \in \mathbb{R}^{N_{h} \times 1}$, $j \in {1, \cdots, n}$, the routing logit $b_{ij}$ between low-level capsure $i$ and high-level capsure $j$ is computed by
        $$b_{ij} = (\vec{c}\_{j}^{h})^{T} S_{ij} \vec{c}\_{i}^{l}$$
        where $S_{ij} \in \mathbb{N_{h} \times N_{l}}$ is the bilinear mapping matrix to be learned.
        
        With routing logits calculated, the candidate vector for high-level capsule $j$ is computed as weighted sum of all low-level capsules
        $$\vec{z}\_{j}^{h} = \sum_{i=1}^{m} w_{ij} S_{ij} \vec{c}\_{i}^{l}$$
        where $w_{ij}$ denotes the weight for connecting low-level capsule $i$ and high-level capsule $j$ and is calculated by performing softmax on routing logits as
        $$w_{ij} = \frac{\exp b_{ij}}{\sum_{k} \exp b_{ik}}$$
        
        Finally, a non-linear "squash" function is applied to obtain the vectors of high-level capsules as
        $$\vec{c}\_{j}^{h} = squash(\vec{z}\_{j}^{h}) = \frac{||\vec{z}\_{j}^{h}||^2}{1 + ||\vec{z}\_{j}^{h}||^2} \frac{\vec{z}\_{j}^{h}}{||\vec{z}\_{j}^{h}||}$$
        
    2. B2I Dynamic Routing

         The original routing algorithm proposed for image data is not directly applicable for processing user behavior data. So, we propose Behavior-to-Interest (B2I) dynamic routing for adaptively aggregating user’s behaviors into interest representation vectors, and it differs from original routing algorithm in three aspects.
         
        1. *Shared bilinear mapping matrix*

            $$b_{ij} = \vec{u}\_{j}^{T} S \vec{e}\_{i}, \qquad i \in \mathcal{I}_{u}, j \in {1, \cdots, K}$$
            where $\vec{e}\_{i} \in \mathbb{R}^{d}$ denotes the embedding of behaviour item $i$, $\vec{u}\_{j} \in \mathbb{R}^{d}$ the vector of interest capsure $j$. The bilinear mapping matrix $S \in \mathbb{R}^{d \times d}$ is shared across each pair of behaviour capsures and interest capsures.
         
        2. *Randomly initialized routing logits*

            Owing to the use of shared bilinear mapping matrix $S$, initializing routing logits to zeros will lead to the same initial interest capsules. To mitigate this phenomenon, we sample a random matrix from gaussian distribution $N(0, \sigma^2)$ for initial routing logits to make initial interest capsules differ from each other.
        
        3. Dynamic interest number

            $$K_{u}^{'} = \max(1, \min(K, \log_{2}(|\mathcal{I}_{u}|)))$$
        
    
    **The whole dynamic routing procedure is listed in the following algorithm**:
    
    <img width="396" alt="image" src="https://user-images.githubusercontent.com/49403324/208393217-f84e73d8-49f1-4859-9895-9dc2d47d2919.png">


4. Label-aware Attention Layer

    Several interest capsules are generated from user’s behavior embeddings through multi-interest extractor layer. Different interest capsules represent different aspects of user interests, and the relevant interest capsule is used for evaluating user’s preference on specific items. Therefore, during training, we design a label-aware attention layer based on scaled dot-product attention to make the target item choose which interest capsule is used.
    
    $$\vec{v}\_{u} = Attention(\vec{e}\_{i}, V_{u}, V_{u}) = V_{u} softmax(pow(V_{u}^{T}\vec{e}\_{i}, p))$$
    where $pow$ denotes element-wise exponentiation operator, $p$ a tunable parameter for adjusting the attention distribution.
    
    <img width="142" alt="image" src="https://user-images.githubusercontent.com/49403324/208394359-1e5ebaff-a37c-4b75-8e4d-ad06b6946690.png">


5. Training & Serving

    With the user vector $\vec{v}\_{u}$ and the label item embedding $\vec{e}\_{i}$ ready, the probability of user $u$ interacting with item $i$ as
    $$Pr(i|u) = Pr(\vec{e}\_{i}|\vec{v}\_{u}) = \frac{\exp (\vec{v}\_{u}^{T} \vec{e}\_{i})}{\sum_{j \in \mathcal{I}} \exp (\vec{v}\_{u}^{T} \vec{e}\_{j})}$$
    
    Then, the overall objective function for training MIND is
    $$L = \sum_{(u,i) \in \mathcal{D}} \log Pr(i | u)$$
    where $D$ is the collections of training data conmtaining user-item interactions.


**Experiments**

