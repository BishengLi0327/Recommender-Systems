# Multi-Interest Network with Dynamic Routing for Recommendation at Tmall (MIND)

https://arxiv.org/abs/1904.08030

**Main Contribution**:

1. To capture diverse intertests of users from user behaviour, this paper designed the multi-interest extractor layer, which utilizes dynamic routing to adaptively aggregate user's historial behaviours into user representation vectors.
2. By using user representation vectors produced by the multi-interest extractor layer and a newly proposed label-aware attention layer, a deep neural network is built for personalized recommendation tasks. Comnpare with existing methods, MIND shows superior performance on several public datasets and one industrial dataset from Tmall.
3. A system is constructed to implement the whole pipeline for data collecting, model training and online serving to deploy MIND for serving billion-scale users at Tmall. The deployed system significantly improves the click-through rate of the home page on Mobile Tmall APP.


**MIND Framework**

<img width="810" alt="image" src="https://user-images.githubusercontent.com/49403324/208366456-f2242c88-df57-4e45-89a3-f69c49528a63.png">


**MIND**

Industrial recommender systems usually consist of the matching stage and the ranking stage, in order to handle the billion-scale of users and items. The matching stage retrieves candidate items relevant to user interests, while the ranking stage sorts candidate items by user interests. Thus, the most critical ability is to model and
represent user interests for either stage.

1. Problem Formalization

    The objective of the matching stage for industrial RS is to retrieve a subset of items from the billion-scale item pool $\mathcal{I}$ for each user $u \in \mathcal{U}$ such that the subset contains only thousands of items and each item is relevant to interests of the user. In order to achieve this objective, historial data generated by RS is collected for building a mathcing machine. Specifically, each instance can be represented by a tuple $(\mathcal{I}\_{u}, \mathcal{P}\_{u}, \mathcal{F}\_{i})$, where $\mathcal{I}\_{u}$ denotes the set of items interacted by user $u$, $\mathcal{P}\_{u}$ the basic profiles of user $u$, $\mathcal{F}\_{i}$ the features of target item.
    
    The core task of MIND is to learn a function for mapping raw features into user representations, which can be formulated as:
    $$V_{u} = f_{user} (\mathcal{I}\_{u}, \mathcal{P}\_{u})$$
    where $V_{u} = (\vec{v}\_{u}^{1}, \cdots, \vec{v}\_{u}^{K}) \in \mathcal{R}^{d \times K}$ denotes the representation vectors of user $u$, $d$ the dimensionality, $K$ the number of representation vectors.
    
    The represenmtation vector of target item $i$ can be obtained by an embedding functionas
    $$\vec{e}\_{i} = f_{item}(\mathcal{F}\_{i})$$
    where $\vec{e}\_{i} \in \mathbb{R}^{d \times 1}$ denotes the representation vector of item $i$.
    
    When user represewntation vectors and item representation vector are learnt, top $N$ candidate items are retrieved according to the scoring function
    $$f_{score}(V_{u}, \vec{e}\_{i}) = \max_{1 \leq k \leq K} \vec{e}\_{i}^{T} \vec{v}\_{u}^{k}$$

2. Embedding & Pooling Layer

    As shown in the above frameworkm, the input of MIND consisits three of three groups
    - user profile $\mathcal{P}\_{u}$
    - user behaviour $\mathcal{I}\_{u}$
    - label item $\mathcal{F}\_{i}$
    Each group contains several categorical id features, and these features are of extremely high dimensionality, MIND adopt the widely used embedding techinque to embed these id features into low-dimension dense vectors. 

3. Multi-Interest Extractor Layer

    


4. Label-aware Attention Layer


5. Training & Serving


6. Connections with Existing Methods


**Wxperiments**

